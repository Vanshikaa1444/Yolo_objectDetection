{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vanshikaa1444/Yolo_objectDetection/blob/main/Yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4801253b-acd4-4d7d-8552-d115a170b3d0",
      "metadata": {
        "id": "4801253b-acd4-4d7d-8552-d115a170b3d0"
      },
      "outputs": [],
      "source": [
        "# Yolo algorithm\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
        "\n",
        "classes = []\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = f.read().splitlines()\n",
        "\n",
        "cap = cv2.VideoCapture('Demo_video.mp4')\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "colors = np.random.uniform(0, 255, size=(100, 3))\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
        "    layerOutputs = net.forward(output_layers_names)\n",
        "\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "\n",
        "    for output in layerOutputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0]*width)\n",
        "                center_y = int(detection[1]*height)\n",
        "                w = int(detection[2]*width)\n",
        "                h = int(detection[3]*height)\n",
        "\n",
        "                x = int(center_x - w/2)\n",
        "                y = int(center_y - h/2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append((float(confidence)))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
        "\n",
        "    if len(indexes)>0:\n",
        "        for i in indexes.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = str(round(confidences[i],2))\n",
        "            color = colors[i]\n",
        "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
        "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
        "\n",
        "    cv2.imshow('Image', img)\n",
        "    key = cv2.waitKey(1)\n",
        "    if key==27:\n",
        "        break\n",
        "    elif key == ord('p'):  # Press 'p' to pause/play\n",
        "        cv2.waitKey(-1)\n",
        "    elif key == ord('f'):  # Press 'f' to fast forward by 5 seconds\n",
        "        current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, current_time_msec + 5000)\n",
        "    elif key == ord('b'):  # Press 'b' to go backward by 5 seconds\n",
        "        current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, max(0, current_time_msec - 5000))\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d05a46-429a-4879-adb3-ef27240c63b3",
      "metadata": {
        "id": "95d05a46-429a-4879-adb3-ef27240c63b3"
      },
      "outputs": [],
      "source": [
        "# with csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
        "\n",
        "classes = []\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = f.read().splitlines()\n",
        "\n",
        "cap = cv2.VideoCapture('Demo_video.mp4')\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "csv_file = open('output.csv', 'w', newline='')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['Frame', 'Class', 'Confidence', 'X', 'Y', 'Width', 'Height'])\n",
        "\n",
        "frame_number = 0\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
        "    layerOutputs = net.forward(output_layers_names)\n",
        "\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "\n",
        "    for output in layerOutputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0]*width)\n",
        "                center_y = int(detection[1]*height)\n",
        "                w = int(detection[2]*width)\n",
        "                h = int(detection[3]*height)\n",
        "\n",
        "                x = int(center_x - w/2)\n",
        "                y = int(center_y - h/2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append((float(confidence)))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
        "\n",
        "    if len(indexes)>0:\n",
        "        for i in indexes.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = round(confidences[i], 2)\n",
        "            color = colors[class_ids[i]]\n",
        "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
        "            cv2.putText(img, label + \" \" + str(confidence), (x, y+20), font, 2, (255,255,255), 2)\n",
        "            csv_writer.writerow([frame_number, label, confidence, x, y, w, h])\n",
        "\n",
        "    cv2.imshow('Image', img)\n",
        "    key = cv2.waitKey(1)\n",
        "    if key==27:\n",
        "        break\n",
        "    elif key == ord('p'):  # Press 'p' to pause/play\n",
        "        cv2.waitKey(-1)\n",
        "    elif key == ord('f'):  # Press 'f' to fast forward by 5 seconds\n",
        "        current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, current_time_msec + 5000)\n",
        "    elif key == ord('b'):  # Press 'b' to go backward by 5 seconds\n",
        "        current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, max(0, current_time_msec - 5000))\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "csv_file.close()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41faf6a1-9eb5-4ed0-9997-637c130dc6a4",
      "metadata": {
        "id": "41faf6a1-9eb5-4ed0-9997-637c130dc6a4"
      },
      "outputs": [],
      "source": [
        "# to display count\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
        "\n",
        "classes = []\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = f.read().splitlines()\n",
        "\n",
        "cap = cv2.VideoCapture('Demo_video.mp4')\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
        "    layerOutputs = net.forward(output_layers_names)\n",
        "\n",
        "    # Dictionary to store object counts for each class in the current frame\n",
        "    frame_object_counts = {class_name: 0 for class_name in classes}\n",
        "\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "\n",
        "    for output in layerOutputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.95:\n",
        "                center_x = int(detection[0]*width)\n",
        "                center_y = int(detection[1]*height)\n",
        "                w = int(detection[2]*width)\n",
        "                h = int(detection[3]*height)\n",
        "\n",
        "                x = int(center_x - w/2)\n",
        "                y = int(center_y - h/2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append((float(confidence)))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "                # Increment object count for the detected class in the current frame\n",
        "                class_name = classes[class_id]\n",
        "                frame_object_counts[class_name] += 1\n",
        "\n",
        "    # Display object counts on the frame for classes present in the current frame\n",
        "    y_offset = 30\n",
        "    for class_name, count in frame_object_counts.items():\n",
        "        if count > 0:\n",
        "            text = f'{class_name}: {count}'\n",
        "            text_size = cv2.getTextSize(text, font, 1, 2)[0]\n",
        "            cv2.rectangle(img, (10, y_offset - text_size[1]), (10 + text_size[0], y_offset + 5), (255, 255, 255), -1)  # White background\n",
        "            cv2.putText(img, text, (10, y_offset), font, 1, (0, 0, 0), 2)  # Change text color to black\n",
        "            y_offset += 20  # Adjust vertical position for next class count\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.7, 0.7)\n",
        "\n",
        "    if len(indexes) > 0:\n",
        "        for i in indexes.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = str(round(confidences[i],2))\n",
        "            color = colors[i]\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "            cv2.putText(img, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.imshow('Image', img)\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == 27:\n",
        "        break\n",
        "    elif key == ord('p'):  # Press 'p' to pause/play\n",
        "        cv2.waitKey(-1)\n",
        "    elif key == ord('f'):  # Press 'f' to fast forward by 5 seconds\n",
        "        current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, current_time_msec + 5000)\n",
        "    elif key == ord('b'):  # Press 'b' to go backward by 5 seconds\n",
        "        current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, max(0, current_time_msec - 5000))\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dec6767-61a3-4588-9fa5-a4d41ef50a3c",
      "metadata": {
        "id": "8dec6767-61a3-4588-9fa5-a4d41ef50a3c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}